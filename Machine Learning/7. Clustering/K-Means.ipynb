{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T11:41:08.045886600Z",
     "start_time": "2023-11-08T11:41:06.843462Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys as sys\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding('utf-8')\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.font_manager import FontProperties \n",
    "from sklearn.cluster import KMeans \n",
    "from scipy.spatial.distance import cdist \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectorize the input documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T11:41:25.576933200Z",
     "start_time": "2023-11-08T11:41:25.571829500Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfidf_vector(corpus_path):\n",
    "    corpus_train=[]\n",
    "    #利用train-corpus提取特征\n",
    "    target_train=[]\n",
    "    for line in open(corpus_path):\n",
    "        line=line.strip().split('\\t')\n",
    "        if len(line)==2:\n",
    "            words=line[1]\n",
    "            category=line[0]\n",
    "            target_train.append(category)\n",
    "            corpus_train.append(words)\n",
    "    print (\"build train-corpus done!!\")\n",
    "    count_v1= CountVectorizer(max_df=0.4,min_df=0.01)\n",
    "    counts_train = count_v1.fit_transform(corpus_train)  \n",
    "    \n",
    "    word_dict={}\n",
    "    for index,word in enumerate(count_v1.get_feature_names()):\n",
    "        word_dict[index]=word\n",
    "    \n",
    "    print (\"the shape of train is \")\n",
    "    print (repr(counts_train.shape))\n",
    "    tfidftransformer = TfidfTransformer()\n",
    "    tfidf_train = tfidftransformer.fit(counts_train).transform(counts_train)\n",
    "    return tfidf_train,word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topic cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T11:41:37.307681300Z",
     "start_time": "2023-11-08T11:41:37.303656Z"
    }
   },
   "outputs": [],
   "source": [
    "def cluster_kmeans(tfidf_train,word_dict,cluster_docs,cluster_keywords,num_clusters):#K均值分类\n",
    "    f_docs=open(cluster_docs,'w+')\n",
    "    km = KMeans(n_clusters=num_clusters)\n",
    "    km.fit(tfidf_train)\n",
    "    clusters = km.labels_.tolist()\n",
    "    cluster_dict={}\n",
    "    order_centroids = km.cluster_centers_.argsort()[:, ::-1]      \n",
    "    doc=1\n",
    "    for cluster in clusters:\n",
    "        f_docs.write(str(str(doc))+','+str(cluster)+'\\n')\n",
    "        doc+=1\n",
    "        if cluster not in cluster_dict:\n",
    "            cluster_dict[cluster]=1\n",
    "        else:\n",
    "            cluster_dict[cluster]+=1\n",
    "    f_docs.close()\n",
    "    cluster=1\n",
    "    \n",
    "    f_clusterwords = open(cluster_keywords,'w+')\n",
    "    for ind in order_centroids: # 每个聚类选 50 个词\n",
    "        words=[]\n",
    "        for index in ind[:50]:\n",
    "            words.append(word_dict[index])\n",
    "        print (cluster),(','.join(words))\n",
    "        f_clusterwords.write(str(cluster)+'\\t'+','.join(words)+'\\n')\n",
    "        cluster+=1\n",
    "        print ('*****'*5)\n",
    "    f_clusterwords.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select the best cluster num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T11:41:52.326809900Z",
     "start_time": "2023-11-08T11:41:52.325362600Z"
    }
   },
   "outputs": [],
   "source": [
    "def best_kmeans(tfidf_matrix,word_dict):  \n",
    "    K = range(1, 10) \n",
    "    meandistortions = [] \n",
    "    for k in K: \n",
    "        print (k),('****'*5)\n",
    "        kmeans = KMeans(n_clusters=k) \n",
    "        kmeans.fit(tfidf_matrix)    \n",
    "        meandistortions.append(sum(np.min(cdist(tfidf_matrix.toarray(), kmeans.cluster_centers_, 'euclidean'), axis=1)) / tfidf_matrix.shape[0]) \n",
    "    plt.plot(K, meandistortions, 'bx-')\n",
    "    plt.grid(True) \n",
    "    plt.xlabel('Number of clusters') \n",
    "    plt.ylabel('Average within-cluster sum of squares') \n",
    "    plt.title('Elbow for Kmeans clustering')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main启动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T11:45:17.312357500Z",
     "start_time": "2023-11-08T11:45:17.259217200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build train-corpus done!!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m cluster_keywords \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mD:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mgithub\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mgaoke966\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mML-NLP\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mMachine Learning\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124m7. Clustering\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mcluster_result_keyword.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      4\u001B[0m num_clusters \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m7\u001B[39m\n\u001B[1;32m----> 5\u001B[0m tfidf_train,word_dict\u001B[38;5;241m=\u001B[39mtfidf_vector(corpus_train)\n\u001B[0;32m      6\u001B[0m best_kmeans(tfidf_train,word_dict)\n\u001B[0;32m      7\u001B[0m cluster_kmeans(tfidf_train,word_dict,cluster_docs,cluster_keywords,num_clusters)\n",
      "Cell \u001B[1;32mIn[2], line 17\u001B[0m, in \u001B[0;36mtfidf_vector\u001B[1;34m(corpus_path)\u001B[0m\n\u001B[0;32m     14\u001B[0m counts_train \u001B[38;5;241m=\u001B[39m count_v1\u001B[38;5;241m.\u001B[39mfit_transform(corpus_train)  \n\u001B[0;32m     16\u001B[0m word_dict\u001B[38;5;241m=\u001B[39m{}\n\u001B[1;32m---> 17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index,word \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(count_v1\u001B[38;5;241m.\u001B[39mget_feature_names()):\n\u001B[0;32m     18\u001B[0m     word_dict[index]\u001B[38;5;241m=\u001B[39mword\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe shape of train is \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'CountVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "corpus_train = \"D:\\\\github\\\\gaoke966\\\\ML-NLP\\\\Machine Learning\\\\7. Clustering\\\\corpus_train.txt\"\n",
    "cluster_docs = \"D:\\\\github\\\\gaoke966\\\\ML-NLP\\Machine Learning\\\\7. Clustering\\\\cluster_result_document.txt\"\n",
    "cluster_keywords = \"D:\\\\github\\\\gaoke966\\\\ML-NLP\\\\Machine Learning\\\\7. Clustering\\\\cluster_result_keyword.txt\"\n",
    "num_clusters = 7\n",
    "tfidf_train,word_dict=tfidf_vector(corpus_train)\n",
    "best_kmeans(tfidf_train,word_dict)\n",
    "cluster_kmeans(tfidf_train,word_dict,cluster_docs,cluster_keywords,num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
